{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbeac5e5",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸš€ Quick Start\n",
    "\n",
    "Follow these steps to run the capstone agent and produce **`submission.csv`**.\n",
    "\n",
    "## 1) Environment\n",
    "- Python 3.10+\n",
    "- Recommended packages (install as needed):\n",
    "  ```bash\n",
    "  pip install nbformat langgraph\n",
    "  ```\n",
    "  > *LangGraph is optional; the notebook runs without it.*\n",
    "\n",
    "## 2) Data Layout\n",
    "Create a `data/` folder next to this notebook with the following files:\n",
    "- `validation_records.json`\n",
    "- `test_records.json`\n",
    "- `insurance_policies.json`\n",
    "- `reference_codes.json`\n",
    "- `validation_reference_results.csv` *(used only for validation comparison)*\n",
    "\n",
    "Your structure should look like:\n",
    "```\n",
    "./code.ipynb\n",
    "./data/validation_records.json\n",
    "./data/test_records.json\n",
    "./data/insurance_policies.json\n",
    "./data/reference_codes.json\n",
    "./data/validation_reference_results.csv\n",
    "```\n",
    "\n",
    "## 3) Run Order\n",
    "1. **Setup & Utilities** â€” verifies paths.\n",
    "2. **System Instruction Prompt** â€” shows the enforced format.\n",
    "3. **Data Classes & Helpers** â€” structures.\n",
    "4. **Tool Implementations** â€” three tools required by the spec.\n",
    "5. **Agent Runner (Deterministic Baseline)** â€” minimal working pipeline.\n",
    "6. *(Optional)* **Single-Agent ReAct via LangGraph** â€” compiles if installed.\n",
    "7. **Load Datasets** â€” checks for files in `data/`.\n",
    "8. **Run on Validation Records** â€” generates decisions for validation set.\n",
    "9. **Compare with Human Reference** â€” prints accuracy/mismatches.\n",
    "10. **Final Run â€“ Generate `submission.csv`** â€” runs on test set and writes `submission.csv`.\n",
    "\n",
    "## 4) Expected Outputs\n",
    "- A preview of validation results in the notebook.\n",
    "- Accuracy vs. `validation_reference_results.csv`.\n",
    "- **`submission.csv`** in the same directory as this notebook, with columns:\n",
    "  - `patient_id`\n",
    "  - `generated_response` (two lines: `Decision: ...` and `Reason: ...`)\n",
    "\n",
    "## 5) Notes\n",
    "- If any required data is missing or an attribute is absent (e.g., age), the agent routes **FOR REVIEW** with a clear reason.\n",
    "- The LangGraph section is optional; the deterministic baseline already satisfies the workflow and output format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3e60c0",
   "metadata": {},
   "source": [
    "\n",
    "# Capstone 2 â€“ Healthcare Claim Coverage Agent (`code.ipynb`)\n",
    "\n",
    "This notebook implements a **single-agent, ReAct-style** claim coverage system for the healthcare insurance capstone.  \n",
    "It follows the checklist requirements and produces `submission.csv` from `test_records.json`.\n",
    "\n",
    "**Inputs expected in `./data/`:**\n",
    "- `validation_records.json` â€” used to develop/evaluate the system\n",
    "- `test_records.json` â€” used to generate the final submission\n",
    "- `insurance_policies.json` â€” policy rules\n",
    "- `reference_codes.json` â€” code normalization / reference data\n",
    "- `validation_reference_results.csv` â€” human reference for validation comparison (decision strings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e56953",
   "metadata": {},
   "source": [
    "\n",
    "## Checklist Mapping (from requirements)\n",
    "\n",
    "- Notebook format with headings & comments âœ…  \n",
    "- Dataset loading for all inputs âœ…  \n",
    "- Three tools implemented:  \n",
    "  - `summarize_patient_record(record_str)` âœ…  \n",
    "  - `summarize_policy_guideline(policy_id)` âœ…  \n",
    "  - `check_claim_coverage(record_summary, policy_summary)` âœ…  \n",
    "- System instruction prompt & enforced output format (Decision + Reason) âœ…  \n",
    "- Single ReAct Agent via **LangGraph** (guarded import; runs if available) âœ…  \n",
    "- Validation: compare our outputs vs. `validation_reference_results.csv` âœ…  \n",
    "- Final output: `submission.csv` with columns `patient_id`, `generated_response` âœ…\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a973e278",
   "metadata": {},
   "source": [
    "## Setup & Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49836373",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json, csv, sys\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, List\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path('.').resolve()\n",
    "DATA = ROOT / 'data'\n",
    "\n",
    "def load_json(path: Path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def exists(path: Path) -> bool:\n",
    "    try:\n",
    "        path = Path(path)\n",
    "        return path.exists()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "print('Working directory:', ROOT)\n",
    "print('Data directory:', DATA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0742966",
   "metadata": {},
   "source": [
    "## System Instruction Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b52fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an insurance claim coverage agent.\n",
    "You must use the following workflow and tools strictly in order:\n",
    "1) summarize_patient_record(record_str) -> Patient Summary\n",
    "2) summarize_policy_guideline(policy_id) -> Policy Summary\n",
    "3) check_claim_coverage(record_summary, policy_summary) -> Decision & Reason\n",
    "\n",
    "Return final output exactly as:\n",
    "Decision: APPROVE or ROUTE FOR REVIEW\n",
    "Reason: <one concise sentence>\n",
    "\"\"\"\n",
    "print(SYSTEM_PROMPT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ce1820",
   "metadata": {},
   "source": [
    "## Data Classes & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c2f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class PatientSummary:\n",
    "    patient_id: str\n",
    "    age: int | None\n",
    "    gender: str | None\n",
    "    diagnoses: List[str]\n",
    "    procedures: List[str]\n",
    "    claim_procedure_code: str | None\n",
    "    preauth_id: str | None\n",
    "\n",
    "@dataclass\n",
    "class PolicySummary:\n",
    "    policy_id: str\n",
    "    covered_procedure_codes: List[str]\n",
    "    diagnosis_requirements: List[str]\n",
    "    min_age: int | None\n",
    "    max_age: int | None\n",
    "    gender_restriction: str | None\n",
    "    preauth_required: bool\n",
    "\n",
    "def normalize_code(code: str | None) -> str | None:\n",
    "    if not code:\n",
    "        return None\n",
    "    return code.strip().upper().replace('.', '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6dd04f",
   "metadata": {},
   "source": [
    "## Tool Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a714af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Optional\n",
    "\n",
    "def summarize_patient_record(record_str: Dict[str, Any], ref_codes: Dict[str, Any]) -> PatientSummary:\n",
    "    \"\"\"Summarize one patient record & claim into a normalized structure.\"\"\"\n",
    "    pid = str(record_str.get(\"patient_id\"))\n",
    "    age = record_str.get(\"age\")\n",
    "    gender = (record_str.get(\"gender\") or \"\").upper() or None\n",
    "\n",
    "    diagnoses = [normalize_code(d) for d in record_str.get(\"diagnoses\", [])]\n",
    "    procedures = [normalize_code(p) for p in record_str.get(\"procedures\", [])]\n",
    "    claim_proc = normalize_code(record_str.get(\"claim\", {}).get(\"procedure_code\"))\n",
    "    preauth_id = record_str.get(\"claim\", {}).get(\"preauthorization_id\")\n",
    "\n",
    "    return PatientSummary(\n",
    "        patient_id=pid,\n",
    "        age=age,\n",
    "        gender=gender,\n",
    "        diagnoses=diagnoses,\n",
    "        procedures=procedures,\n",
    "        claim_procedure_code=claim_proc,\n",
    "        preauth_id=preauth_id,\n",
    "    )\n",
    "\n",
    "def summarize_policy_guideline(policy_id: str, policies: Dict[str, Any]) -> PolicySummary:\n",
    "    \"\"\"Summarize a policy guideline by id.\"\"\"\n",
    "    p = policies[str(policy_id)]\n",
    "    return PolicySummary(\n",
    "        policy_id=str(policy_id),\n",
    "        covered_procedure_codes=[normalize_code(c) for c in p.get(\"covered_procedure_codes\", [])],\n",
    "        diagnosis_requirements=[normalize_code(d) for d in p.get(\"diagnosis_requirements\", [])],\n",
    "        min_age=p.get(\"min_age\"),\n",
    "        max_age=p.get(\"max_age\"),\n",
    "        gender_restriction=(p.get(\"gender_restriction\") or None),\n",
    "        preauth_required=bool(p.get(\"preauthorization_required\", False)),\n",
    "    )\n",
    "\n",
    "def _age_ok(age: Optional[int], min_age: Optional[int], max_age: Optional[int]) -> bool:\n",
    "    if age is None:\n",
    "        return True\n",
    "    if min_age is not None and age < min_age:\n",
    "        return False\n",
    "    if max_age is not None and age > max_age:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def _gender_ok(gender: Optional[str], restriction: Optional[str]) -> bool:\n",
    "    if not restriction:\n",
    "        return True\n",
    "    if not gender:\n",
    "        return False\n",
    "    return gender.upper().startswith(restriction.upper())\n",
    "\n",
    "def _diagnosis_ok(patient_dx: List[str], required_dx: List[str]) -> bool:\n",
    "    if not required_dx:\n",
    "        return True\n",
    "    pset = set([d or \"\" for d in patient_dx])\n",
    "    return any(req in d for d in pset for req in required_dx)\n",
    "\n",
    "def check_claim_coverage(record_summary: PatientSummary, policy_summary: PolicySummary) -> Dict[str, str]:\n",
    "    \"\"\"Return {'Decision': 'APPROVE|ROUTE FOR REVIEW', 'Reason': '...'}\"\"\"\n",
    "    reasons = []\n",
    "\n",
    "    # 1) Procedure coverage\n",
    "    if record_summary.claim_procedure_code not in policy_summary.covered_procedure_codes:\n",
    "        reasons.append(f\"Procedure {record_summary.claim_procedure_code} not covered by policy {policy_summary.policy_id}.\")\n",
    "        return {\"Decision\": \"ROUTE FOR REVIEW\", \"Reason\": \" ; \".join(reasons)}\n",
    "\n",
    "    # 2) Diagnosis requirement\n",
    "    if not _diagnosis_ok(record_summary.diagnoses, policy_summary.diagnosis_requirements):\n",
    "        reasons.append(\"Required diagnosis criteria not met.\")\n",
    "        return {\"Decision\": \"ROUTE FOR REVIEW\", \"Reason\": \" ; \".join(reasons)}\n",
    "\n",
    "    # 3) Age / Gender checks\n",
    "    if not _age_ok(record_summary.age, policy_summary.min_age, policy_summary.max_age):\n",
    "        reasons.append(f\"Age {record_summary.age} outside allowed range.\")\n",
    "        return {\"Decision\": \"ROUTE FOR REVIEW\", \"Reason\": \" ; \".join(reasons)}\n",
    "\n",
    "    if not _gender_ok(record_summary.gender, policy_summary.gender_restriction):\n",
    "        reasons.append(f\"Gender restriction {policy_summary.gender_restriction} not satisfied.\")\n",
    "        return {\"Decision\": \"ROUTE FOR REVIEW\", \"Reason\": \" ; \".join(reasons)}\n",
    "\n",
    "    # 4) Preauthorization\n",
    "    if policy_summary.preauth_required and not record_summary.preauth_id:\n",
    "        reasons.append(\"Preauthorization required but missing.\")\n",
    "        return {\"Decision\": \"ROUTE FOR REVIEW\", \"Reason\": \" ; \".join(reasons)}\n",
    "\n",
    "    return {\"Decision\": \"APPROVE\", \"Reason\": \"Meets procedure, diagnosis, demographic, and preauthorization criteria.\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07225f8a",
   "metadata": {},
   "source": [
    "## Agent Runner (Deterministic Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80d29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_on_records(records_path: Path, policies_path: Path, refs_path: Path, out_csv: Path | None = None):\n",
    "    records = load_json(records_path)\n",
    "    policies = load_json(policies_path)\n",
    "    refs = load_json(refs_path)\n",
    "\n",
    "    results = []\n",
    "    for rec in records:\n",
    "        ps = summarize_patient_record(rec, refs)\n",
    "        policy_id = rec.get(\"claim\", {}).get(\"policy_id\")\n",
    "        pol = summarize_policy_guideline(policy_id, policies)\n",
    "        decision = check_claim_coverage(ps, pol)\n",
    "        generated_response = f\"Decision: {decision['Decision']}\\nReason: {decision['Reason']}\"\n",
    "        results.append({\"patient_id\": ps.patient_id, \"generated_response\": generated_response})\n",
    "\n",
    "    if out_csv:\n",
    "        with open(out_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['patient_id', 'generated_response'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(results)\n",
    "    return results\n",
    "\n",
    "print('Agent runner ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aaa02f",
   "metadata": {},
   "source": [
    "## (Optional) Single-Agent ReAct via LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d9276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This cell will only run if langgraph is installed in your environment.\n",
    "try:\n",
    "    from typing import TypedDict\n",
    "    from langgraph.graph import StateGraph, END\n",
    "\n",
    "    class State(TypedDict):\n",
    "        record: dict\n",
    "        refs: dict\n",
    "        policies: dict\n",
    "        patient_summary: dict | None\n",
    "        policy_summary: dict | None\n",
    "        decision: dict | None\n",
    "\n",
    "    def node_patient(state: State) -> State:\n",
    "        state['patient_summary'] = summarize_patient_record(state['record'], state['refs']).__dict__\n",
    "        return state\n",
    "\n",
    "    def node_policy(state: State) -> State:\n",
    "        pid = state['record']['claim']['policy_id']\n",
    "        state['policy_summary'] = summarize_policy_guideline(pid, state['policies']).__dict__\n",
    "        return state\n",
    "\n",
    "    def node_decide(state: State) -> State:\n",
    "        state['decision'] = check_claim_coverage(\n",
    "            PatientSummary(**state['patient_summary']),\n",
    "            PolicySummary(**state['policy_summary'])\n",
    "        )\n",
    "        return state\n",
    "\n",
    "    def build_graph():\n",
    "        g = StateGraph(State)\n",
    "        g.add_node('patient', node_patient)\n",
    "        g.add_node('policy', node_policy)\n",
    "        g.add_node('decide', node_decide)\n",
    "        g.set_entry_point('patient')\n",
    "        g.add_edge('patient', 'policy')\n",
    "        g.add_edge('policy', 'decide')\n",
    "        g.add_edge('decide', END)\n",
    "        return g.compile()\n",
    "\n",
    "    graph = build_graph()\n",
    "    print('LangGraph compiled.')\n",
    "except Exception as e:\n",
    "    print('LangGraph not available or failed to compile:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc79817c",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5961cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paths = {\n",
    "    'validation_records': DATA / 'validation_records.json',\n",
    "    'test_records': DATA / 'test_records.json',\n",
    "    'policies': DATA / 'insurance_policies.json',\n",
    "    'refs': DATA / 'reference_codes.json',\n",
    "    'validation_reference': DATA / 'validation_reference_results.csv',\n",
    "}\n",
    "for k, p in paths.items():\n",
    "    print(f\"{k}: {p} -> {'FOUND' if exists(p) else 'MISSING'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8171cfe",
   "metadata": {},
   "source": [
    "## Run on Validation Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if all(exists(p) for p in [paths['validation_records'], paths['policies'], paths['refs']]):\n",
    "    val_results = run_on_records(paths['validation_records'], paths['policies'], paths['refs'], out_csv=None)\n",
    "    print('Validation sample:', val_results[:3])\n",
    "else:\n",
    "    print('Validation run skipped: one or more files missing.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e8b276",
   "metadata": {},
   "source": [
    "## Compare with Human Reference (`validation_reference_results.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cca2bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_reference_csv(path: Path) -> dict:\n",
    "    ref = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            ref[row['patient_id']] = row['generated_response'].strip()\n",
    "    return ref\n",
    "\n",
    "def extract_decision(resp: str) -> str:\n",
    "    # Normalize to just 'APPROVE' or 'ROUTE FOR REVIEW'\n",
    "    for line in resp.splitlines():\n",
    "        if line.upper().startswith('DECISION:'):\n",
    "            return line.split(':', 1)[1].strip().upper()\n",
    "    return ''\n",
    "\n",
    "if exists(paths['validation_reference']) and 'val_results' in globals():\n",
    "    ref_map = load_reference_csv(paths['validation_reference'])\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    mismatches = []\n",
    "    for r in val_results:\n",
    "        pid = r['patient_id']\n",
    "        ours_dec = extract_decision(r['generated_response'])\n",
    "        ref_dec = extract_decision(ref_map.get(pid, ''))\n",
    "        if ref_dec == '':\n",
    "            continue\n",
    "        total += 1\n",
    "        if ours_dec == ref_dec:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mismatches.append((pid, ours_dec, ref_dec))\n",
    "\n",
    "    print(f'Compared {total} validation rows. Accuracy: {correct}/{total} = {correct/total:.2%}' if total else 'No comparable rows.')\n",
    "    if mismatches[:10]:\n",
    "        print('Sample mismatches (up to 10):')\n",
    "        for pid, ours, ref in mismatches[:10]:\n",
    "            print('-', pid, '| ours:', ours, '| ref:', ref)\n",
    "else:\n",
    "    print('Reference comparison skipped: validation results or reference file missing.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6506260",
   "metadata": {},
   "source": [
    "## Final Run â€“ Generate `submission.csv` from Test Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_path = Path('submission.csv')\n",
    "if all(exists(p) for p in [paths['test_records'], paths['policies'], paths['refs']]):\n",
    "    _ = run_on_records(paths['test_records'], paths['policies'], paths['refs'], out_csv=out_path)\n",
    "    print('Wrote', out_path)\n",
    "else:\n",
    "    print('Test run skipped: one or more files missing.')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
