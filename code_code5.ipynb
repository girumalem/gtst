{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a410b0",
   "metadata": {},
   "source": [
    "\n",
    "# Capstone — Healthcare Claim Coverage Agent (Parallelized Runner, Fully Commented)\n",
    "\n",
    "This notebook implements **one ReAct agent** that can call **three tools** to evaluate insurance claim coverage against policy rules.\n",
    "The logic is identical to `code_code4.ipynb`; the only difference is that **every line is heavily commented** to help a junior developer follow the flow and explain it.\n",
    "\n",
    "## Overall design & reasoning\n",
    "\n",
    "- **Single source of truth for policies:** We parse policy JSON once into a fast **index** keyed by normalized `policy_id`. Lookups are O(1) and robust to different input shapes.\n",
    "- **Normalize early:** Real-world data is messy. We normalize dates, sex, ICD and CPT codes *before* any rule checks. This keeps the checker deterministic and simple.\n",
    "- **Three focused tools:**  \n",
    "  1. `summarize_patient_record` — shape one raw claim into a clean dict.  \n",
    "  2. `summarize_policy_guideline` — fetch policy rules by `policy_id`.  \n",
    "  3. `check_claim_coverage` — decide **APPROVE** vs **ROUTE FOR REVIEW** with a concise reason.\n",
    "- **Strict agent prompt:** We instruct the agent to always call tools in the same order and to produce a fixed output format. This reduces LLM variance.\n",
    "- **Parallel execution:** LLM round-trips dominate latency. We use `ThreadPoolExecutor` to run multiple records concurrently, without changing any logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a39ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports & path constants ===\n",
    "from __future__ import annotations  # allows forward references in type hints (Python <3.11)\n",
    "from typing import Dict, Any, List, Optional, Tuple  # for clear type annotations\n",
    "import os, json, csv, re, time  # stdlib utilities: file ops, JSON, CSV, regex, timing\n",
    "from datetime import datetime  # for parsing/computing dates and ages\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed  # simple thread-based parallelism\n",
    "\n",
    "# LangChain / LangGraph building blocks\n",
    "from langchain_core.tools import tool  # decorator to expose Python functions as LLM-callable tools\n",
    "from langchain_core.messages import SystemMessage, HumanMessage  # message primitives for agent I/O\n",
    "from langgraph.prebuilt import create_react_agent  # prebuilt ReAct-style agent constructor\n",
    "\n",
    "# --- Relative paths to all project JSONs/outputs ---\n",
    "DATA_DIR = './Data'  # convention from the project: all input/output JSON/CSV live here\n",
    "REFERENCE_CODES_PATH = os.path.join(DATA_DIR, 'reference_codes.json')  # ICD/CPT lookups (optional)\n",
    "POLICIES_PATH        = os.path.join(DATA_DIR, 'insurance_policies.json')  # plan benefit rules\n",
    "VALIDATION_PATH      = os.path.join(DATA_DIR, 'validation_records.json')  # small set for preview/debug\n",
    "TEST_PATH            = os.path.join(DATA_DIR, 'test_records.json')  # full test set used for submission\n",
    "SUBMISSION_PATH      = os.path.join(DATA_DIR, 'submission.csv')  # required output file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79917e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load JSON helpers & reference dictionaries ===\n",
    "def _safe_load(path: str, default):\n",
    "    \"\"\"Best-effort JSON loader.\n",
    "    If loading fails (file missing, bad JSON, etc.), we print a warning and return `default`.\n",
    "    This keeps the notebook resilient to environment differences.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)  # parse JSON into Python dict/list\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not load {path}: {e}\")\n",
    "        return default\n",
    "\n",
    "# Load all inputs up-front so later cells can rely on them.\n",
    "reference_codes: Dict[str, Any] = _safe_load(REFERENCE_CODES_PATH, {})  # may contain icd/cpt maps\n",
    "policies_raw:    Dict[str, Any] = _safe_load(POLICIES_PATH, {})         # raw policy JSON (varied shapes)\n",
    "val_records:     List[Dict[str, Any]] = _safe_load(VALIDATION_PATH, []) # validation sample records\n",
    "test_records:    List[Dict[str, Any]] = _safe_load(TEST_PATH, [])       # test records to score\n",
    "\n",
    "# Optional name maps for codes (used to filter unknowns, but not strictly required)\n",
    "ICD_TO_NAME: Dict[str, str] = reference_codes.get('diagnosis_codes', {}) or reference_codes.get('icd10', {})\n",
    "CPT_TO_NAME: Dict[str, str] = reference_codes.get('procedure_codes', {}) or reference_codes.get('cpt', {})\n",
    "\n",
    "print(\n",
    "    f\"Loaded: reference_codes={bool(reference_codes)}, \"\n",
    "    f\"policies={bool(policies_raw)}, \"\n",
    "    f\"validation_records={len(val_records)}, test_records={len(test_records)}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb3c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helpers for normalization + building a fast policy index ===\n",
    "\n",
    "# We accept many date formats because upstream feeds are inconsistent.\n",
    "DATE_PATTERNS = ['%Y-%m-%d','%m/%d/%Y','%d/%m/%Y','%Y/%m/%d']\n",
    "\n",
    "def parse_date_maybe(s: Any) -> Optional[datetime]:\n",
    "    \"\"\"Try to parse a date string using several formats, including bare YYYYMMDD.\n",
    "    Returns a `datetime` on success, otherwise `None` (non-throwing).\n",
    "    \"\"\"\n",
    "    if not s:\n",
    "        return None  # early exit for None/empty values\n",
    "    s = str(s).strip()  # normalize whitespace and ensure str\n",
    "    for pat in DATE_PATTERNS:\n",
    "        try:\n",
    "            return datetime.strptime(s, pat)  # first pattern that works wins\n",
    "        except Exception:\n",
    "            pass  # silently try next pattern\n",
    "    # Fallback: accept compact YYYYMMDD (e.g., \"20250130\")\n",
    "    m = re.fullmatch(r'(\\d{4})(\\d{2})(\\d{2})', s)\n",
    "    if m:\n",
    "        try:\n",
    "            return datetime(int(m.group(1)), int(m.group(2)), int(m.group(3)))\n",
    "        except Exception:\n",
    "            return None  # invalid month/day -> None\n",
    "    return None\n",
    "\n",
    "def age_from_dob(dob: Optional[datetime], ref: Optional[datetime] = None) -> Optional[int]:\n",
    "    \"\"\"Compute age in whole years at `ref` date (or today if `ref` is None).\n",
    "    Returns None if DOB is missing or the computed age is not sane (negative/too large).\n",
    "    \"\"\"\n",
    "    if not dob:\n",
    "        return None\n",
    "    ref = ref or datetime.utcnow()  # default to now if no service date is provided\n",
    "    # Standard age calc: subtract years, minus 1 if birthday hasn't occurred yet this year\n",
    "    years = ref.year - dob.year - ((ref.month, ref.day) < (dob.month, dob.day))\n",
    "    return years if 0 <= years < 150 else None  # sanity bounds\n",
    "\n",
    "def sex_normalize(s: Any) -> str:\n",
    "    \"\"\"Return canonical 'M'/'F'/'U' from various inputs (e.g., 'male', 'FEMALE', None).\"\"\"\n",
    "    if s is None:\n",
    "        return 'U'\n",
    "    s_up = str(s).strip().upper()\n",
    "    if s_up in {'M','MALE'}:\n",
    "        return 'M'\n",
    "    if s_up in {'F','FEMALE'}:\n",
    "        return 'F'\n",
    "    return 'U'  # unknown/other\n",
    "\n",
    "def icd_dot_normalize(code: Any) -> str:\n",
    "    \"\"\"Normalize ICD-like codes (e.g., 'I200' -> 'I20.0').\n",
    "    We uppercase, strip, and insert a dot after the 3rd char when the shape matches.\n",
    "    \"\"\"\n",
    "    c = str(code).strip().upper()\n",
    "    if re.fullmatch(r'[A-Z]\\d{3,6}', c) and '.' not in c and len(c) >= 4:\n",
    "        return c[:3] + '.' + c[3:]\n",
    "    return c\n",
    "\n",
    "def _norm_pid(pid: Optional[str]) -> Optional[str]:\n",
    "    \"\"\"Normalize policy IDs by stripping dashes/underscores/spaces and uppercasing.\n",
    "    This avoids lookup mismatches like 'pol-123' vs 'POL123'.\n",
    "    \"\"\"\n",
    "    if not pid:\n",
    "        return None\n",
    "    return re.sub(r'[-_\\s]', '', str(pid)).upper()\n",
    "\n",
    "def _extract_rules(obj: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Given one policy object, extract a list of normalized rule dicts.\n",
    "    Each rule captures: procedure, acceptable diagnoses, age range, sex constraint, preauth.\n",
    "    \"\"\"\n",
    "    rules: List[Dict[str, Any]] = []\n",
    "    items = obj.get('covered_procedures') or []  # common field for rule list\n",
    "    if isinstance(items, list):\n",
    "        for it in items:\n",
    "            if not isinstance(it, dict):\n",
    "                continue  # skip malformed entries defensively\n",
    "            # The procedure code is the anchor for the rule\n",
    "            proc = str(it.get('procedure_code') or it.get('procedure') or '').strip()\n",
    "            if not proc:\n",
    "                continue  # rule without a procedure makes no sense\n",
    "\n",
    "            # Accept diagnoses list or delimited string; normalize each ICD code\n",
    "            diags = it.get('covered_diagnoses') or it.get('diagnoses') or []\n",
    "            if isinstance(diags, str):\n",
    "                diags = [d for d in re.split(r'[;,.\\s]+', diags) if d]\n",
    "            diags = [icd_dot_normalize(d) for d in diags]\n",
    "\n",
    "            # Optional age constraints\n",
    "            ar = it.get('age_range') or []\n",
    "            age_min = None; age_max = None\n",
    "            if isinstance(ar, list) and len(ar) >= 2:\n",
    "                try:\n",
    "                    age_min = int(ar[0])\n",
    "                except Exception:\n",
    "                    pass\n",
    "                try:\n",
    "                    age_max = int(ar[1])\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Optional sex constraint ('M', 'F', or 'Any')\n",
    "            sex_raw = str(it.get('gender') or it.get('sex') or 'Any').strip().upper()\n",
    "            sex_rule = 'ANY'\n",
    "            if sex_raw.startswith('M'):\n",
    "                sex_rule = 'M'\n",
    "            elif sex_raw.startswith('F'):\n",
    "                sex_rule = 'F'\n",
    "\n",
    "            # Whether preauthorization is required by policy for this procedure\n",
    "            preauth_required = bool(it.get('requires_preauthorization') or it.get('preauth_required') or False)\n",
    "\n",
    "            # Append a normalized rule record\n",
    "            rules.append({\n",
    "                'procedure': proc,\n",
    "                'diagnoses': diags,\n",
    "                'age_min': age_min,\n",
    "                'age_max': age_max,\n",
    "                'sex': sex_rule,\n",
    "                'preauth_required': preauth_required\n",
    "            })\n",
    "    return rules\n",
    "\n",
    "def build_policy_index(raw: Any) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"Turn raw policies (various shapes) into a dict keyed by normalized policy_id.\n",
    "    Accepts dict with 'policies', dict-of-dicts, or list.\n",
    "    \"\"\"\n",
    "    index: Dict[str, Dict[str, Any]] = {}\n",
    "    # 1) Common shape: { \"policies\": [ {...}, {...} ] }\n",
    "    if isinstance(raw, dict) and 'policies' in raw and isinstance(raw['policies'], list):\n",
    "        src_list = raw['policies']\n",
    "    # 2) Dict-of-dicts: { \"POL123\": {...}, \"POL456\": {...} }\n",
    "    elif isinstance(raw, dict):\n",
    "        src_list = []\n",
    "        for k, v in raw.items():\n",
    "            if isinstance(v, dict):\n",
    "                v = dict(v)  # copy to avoid mutating input\n",
    "                v.setdefault('policy_id', v.get('policyId') or v.get('id') or k)  # synthesize id if needed\n",
    "                src_list.append(v)\n",
    "    # 3) Already a list\n",
    "    elif isinstance(raw, list):\n",
    "        src_list = raw\n",
    "    else:\n",
    "        src_list = []  # unknown shape -> empty\n",
    "\n",
    "    # Normalize each policy and insert into index\n",
    "    for obj in src_list:\n",
    "        if not isinstance(obj, dict):\n",
    "            continue\n",
    "        pid = _norm_pid(\n",
    "            obj.get('policy_id') or obj.get('policyId') or obj.get('id') or obj.get('code') or obj.get('policy_code')\n",
    "        )\n",
    "        if not pid:\n",
    "            continue  # cannot index without an id\n",
    "        index[pid] = {\n",
    "            'policy_id': pid,\n",
    "            'plan_name': obj.get('plan_name') or obj.get('title') or '',  # human-friendly optional\n",
    "            'rules': _extract_rules(obj)\n",
    "        }\n",
    "    return index\n",
    "\n",
    "# Build once at import time for fast lookups during processing\n",
    "POLICY_INDEX: Dict[str, Dict[str, Any]] = build_policy_index(policies_raw)\n",
    "print(f\"Policy index contains {len(POLICY_INDEX)} policies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271ebf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Tools exposed to the agent ===\n",
    "# Tools are plain Python functions decorated with @tool, which lets the agent call them.\n",
    "\n",
    "@tool\n",
    "def summarize_patient_record(record_str: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Normalize a raw patient claim record into a consistent dict the checker can use.\n",
    "    - Parses JSON\n",
    "    - Computes age if missing (using DOB + service date)\n",
    "    - Normalizes sex and diagnosis/procedure codes\n",
    "    - Flattens various preauth flags into one boolean\n",
    "    \"\"\"\n",
    "    # Parse the raw JSON string into a Python dict; tolerate errors by returning an error object\n",
    "    try:\n",
    "        rec = json.loads(record_str)\n",
    "    except Exception:\n",
    "        return {'error': 'invalid JSON'}\n",
    "\n",
    "    # Prefer explicit age when present; otherwise compute from DOB and a reference date\n",
    "    age = rec.get('age')\n",
    "    if age is None:\n",
    "        dob = rec.get('date_of_birth') or rec.get('dob')\n",
    "        svc = rec.get('date_of_service') or rec.get('service_date') or rec.get('claim_date')\n",
    "        if dob:\n",
    "            age = age_from_dob(parse_date_maybe(dob), parse_date_maybe(svc))\n",
    "\n",
    "    # Normalize sex to one of 'M','F','U'\n",
    "    sex = sex_normalize(rec.get('gender') or rec.get('sex'))\n",
    "\n",
    "    # Collect diagnoses, normalize ICD formatting, optionally filter to known references\n",
    "    dx  = rec.get('diagnosis_codes') or rec.get('diagnoses') or []\n",
    "    dx  = [icd_dot_normalize(d) for d in dx]\n",
    "    if ICD_TO_NAME:\n",
    "        dx = [d for d in dx if d in ICD_TO_NAME]\n",
    "\n",
    "    # Collect procedures, coerce to strings, optionally filter to known CPT or 5-digit fallback\n",
    "    cpt = rec.get('procedure_codes') or rec.get('procedures') or []\n",
    "    cpt = [str(x) for x in cpt]\n",
    "    if CPT_TO_NAME:\n",
    "        keep = [c for c in cpt if c in CPT_TO_NAME]\n",
    "        cpt = keep if keep else [c for c in cpt if re.fullmatch(r'\\d{5}', c)]\n",
    "\n",
    "    # Collapse multiple potential flags into a single boolean \"preauth provided\" signal\n",
    "    preauth = rec.get('preauthorization_obtained') or rec.get('preauth_provided') or rec.get('authorization_provided')\n",
    "    preauth = bool(preauth)\n",
    "\n",
    "    # Return a clean summary; note policy_id is normalized for reliable index lookup\n",
    "    return {\n",
    "        'patient_id': rec.get('patient_id') or rec.get('id'),\n",
    "        'policy_id': _norm_pid(rec.get('insurance_policy_id') or rec.get('policy_id') or rec.get('plan_id')),\n",
    "        'age': age,\n",
    "        'sex': sex,\n",
    "        'diagnoses': dx,\n",
    "        'procedures': cpt,\n",
    "        'preauth': preauth\n",
    "    }\n",
    "\n",
    "@tool\n",
    "def summarize_policy_guideline(policy_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch normalized rules for the given policy by ID.\n",
    "    Returns a dict with 'policy_id' and 'rules', or an error if the policy is unknown.\n",
    "    \"\"\"\n",
    "    pid = _norm_pid(policy_id)  # normalize incoming id to match index keys\n",
    "    pol = POLICY_INDEX.get(pid)  # O(1) dictionary lookup\n",
    "    if not pol:\n",
    "        return {'error': f'Unknown policy_id {policy_id}'}\n",
    "    return {'policy_id': pid, 'rules': pol.get('rules', [])}\n",
    "\n",
    "def _rule_covers(record: Dict[str, Any], rule: Dict[str, Any]) -> Tuple[bool, Optional[str]]:\n",
    "    \"\"\"Evaluate whether a single policy rule covers this claim summary.\n",
    "    Returns (True, None) if covered, else (False, reason) for the first failing condition.\n",
    "    \"\"\"\n",
    "    # Convert lists to sets for efficient membership/intersection checks\n",
    "    cpts = set(record.get('procedures', []))\n",
    "    dxs  = set(record.get('diagnoses', []))\n",
    "    age  = record.get('age')\n",
    "    sex  = (record.get('sex') or 'U').upper()\n",
    "    pre  = bool(record.get('preauth', False))\n",
    "\n",
    "    # If the billed CPT isn't the one this rule covers, it's a non-match (not an error)\n",
    "    if rule['procedure'] not in cpts:\n",
    "        return False, None\n",
    "\n",
    "    # If rule specifies diagnoses, at least one must be present in the claim\n",
    "    rdx = set(rule.get('diagnoses', []))\n",
    "    if rdx and not (dxs & rdx):  # empty rdx means \"no diagnosis constraint\"\n",
    "        return False, f\"Diagnosis mismatch for CPT {rule['procedure']}.\"\n",
    "\n",
    "    # Respect age bounds when the claim has a computable age\n",
    "    if age is not None:\n",
    "        if rule.get('age_min') is not None and age < rule['age_min']:\n",
    "            return False, f\"Patient age {age} below covered minimum for CPT {rule['procedure']}.\"\n",
    "        if rule.get('age_max') is not None and age > rule['age_max']:\n",
    "            return False, f\"Patient age {age} exceeds covered maximum for CPT {rule['procedure']}.\"\n",
    "\n",
    "    # Enforce sex restriction when specified by the rule\n",
    "    if rule.get('sex') in {'M','F'} and sex != rule['sex']:\n",
    "        return False, f\"Sex restriction {rule['sex']} for CPT {rule['procedure']}.\"\n",
    "\n",
    "    # If preauth is required by policy, it must be present on the claim\n",
    "    if rule.get('preauth_required') and not pre:\n",
    "        return False, f\"Preauthorization required for CPT {rule['procedure']} but not provided.\"\n",
    "\n",
    "    # All constraints satisfied → this rule covers the claim for that CPT\n",
    "    return True, None\n",
    "\n",
    "@tool\n",
    "def check_claim_coverage(record_summary: Dict[str, Any], policy_summary: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Decide **APPROVE** vs **ROUTE FOR REVIEW** for a claim by comparing the record summary\n",
    "    to the set of rules returned for the policy.\n",
    "    \"\"\"\n",
    "    # If policy lookup failed, we cannot safely approve\n",
    "    if policy_summary.get('error'):\n",
    "        return {'decision':'ROUTE FOR REVIEW','reason':'Unknown policy_id.'}\n",
    "\n",
    "    # Extract rule list; an empty rule set is ambiguous → route for review\n",
    "    rules = policy_summary.get('rules', [])\n",
    "    if not rules:\n",
    "        return {'decision':'ROUTE FOR REVIEW','reason':'Policy does not define covered procedures.'}\n",
    "\n",
    "    # For every billed CPT in the claim, at least one rule must cover it fully\n",
    "    for cpt in record_summary.get('procedures', []):\n",
    "        # Candidate rules are those whose 'procedure' equals the CPT\n",
    "        cand = [r for r in rules if r.get('procedure') == cpt]\n",
    "        if not cand:\n",
    "            return {'decision':'ROUTE FOR REVIEW','reason': f'The claim for CPT code {cpt} is not covered by the policy.'}\n",
    "\n",
    "        # Try each candidate rule until one covers; remember the first failure reason for helpful feedback\n",
    "        ok_any = False; first_reason = None\n",
    "        for r in cand:\n",
    "            ok, why = _rule_covers(record_summary, r)\n",
    "            if ok:\n",
    "                ok_any = True; break\n",
    "            if first_reason is None:\n",
    "                first_reason = why\n",
    "        if not ok_any:\n",
    "            return {'decision':'ROUTE FOR REVIEW','reason': first_reason or f'The claim for CPT code {cpt} does not meet policy requirements.'}\n",
    "\n",
    "    # If we reach here, every billed CPT is covered by at least one rule → approve\n",
    "    cpts = record_summary.get('procedures', [])\n",
    "    detail = f'The claim for CPT code {cpts[0]} is approved.' if cpts else 'Meets policy criteria.'\n",
    "    return {'decision':'APPROVE','reason': detail}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb395176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Agent wiring + parallelized runner ===\n",
    "\n",
    "# Toolbox given to the agent: the only three functions it is allowed to call.\n",
    "TOOLS = [summarize_patient_record, summarize_policy_guideline, check_claim_coverage]\n",
    "\n",
    "# System prompt: this acts like the \"SOP\" for the agent. It enforces tool order and a fixed output shape.\n",
    "AGENT_SYS_TEXT = (\n",
    "    \"You are an insurance claims agent.\\n\"\n",
    "    \"You MUST always call tools in this order for each record:\\n\"\n",
    "    \"  1) summarize_patient_record -> on the raw JSON string of the record\\n\"\n",
    "    \"  2) summarize_policy_guideline -> with the policy_id from step 1\\n\"\n",
    "    \"  3) check_claim_coverage -> with outputs of steps 1 & 2\\n\"\n",
    "    \"When you have enough information, output the FINAL answer in exactly this format:\\n\"\n",
    "    \"- Decision: APPROVE | ROUTE FOR REVIEW\\n\"\n",
    "    \"- Reason: \\n\"\n",
    "    \"Rules:\\n\"\n",
    "    \"- Do not invent policy data. If policy_id is missing/unknown, route for review.\\n\"\n",
    "    \"- Keep the reason short and specific.\\n\"\n",
    ")\n",
    "\n",
    "# Create the ReAct agent from the existing chat client.\n",
    "# Assumption: the user already defined `chat_client` (e.g., OpenAI client) in this runtime.\n",
    "try:\n",
    "    agent = create_react_agent(chat_client, TOOLS)\n",
    "except NameError:\n",
    "    # Provide a clearer error for users: they must define `chat_client` in their environment.\n",
    "    raise RuntimeError(\"Expected an existing `chat_client` instance. Define it before running this cell.\")\n",
    "\n",
    "def _process_record(agent, rec: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"Helper: run the agent on a **single** record and extract the final response text.\"\"\"\n",
    "    rec_str = json.dumps(rec, ensure_ascii=False)  # JSON text becomes the human message payload\n",
    "    messages = [\n",
    "        SystemMessage(content=AGENT_SYS_TEXT),  # strict instructions to keep the agent on-rails\n",
    "        HumanMessage(content=f\"Process this record:\\n{rec_str}\")  # the actual record to process\n",
    "    ]\n",
    "    out = agent.invoke({\"messages\": messages})  # synchronous call; agent internally calls tools\n",
    "    # Depending on versions, `out` can be a dict with messages or an object with .content; handle both\n",
    "    final = (\n",
    "        out[\"messages\"][-1].content\n",
    "        if isinstance(out, dict) and \"messages\" in out\n",
    "        else getattr(out, \"content\", str(out))\n",
    "    )\n",
    "    return {\n",
    "        \"patient_id\": rec.get(\"patient_id\") or rec.get(\"id\"),  # keep id for output mapping\n",
    "        \"generated_response\": final  # the decision text (Decision/Reason)\n",
    "    }\n",
    "\n",
    "def run_agent_on_records(agent, records: List[Dict[str, Any]], max_workers: int = 6) -> List[Dict[str, str]]:\n",
    "    \"\"\"Run the agent over many records using a thread pool for concurrency.\n",
    "    - We keep logic identical to the sequential version; only execution model changes (parallel).\n",
    "    - `max_workers` controls parallelism; tune based on API rate limits and runtime environment.\n",
    "    \"\"\"\n",
    "    results: List[Optional[Dict[str, str]]] = [None] * len(records)  # pre-size result list to preserve order\n",
    "    if not records:\n",
    "        return []\n",
    "\n",
    "    # Warm up the first record to establish network connections and reduce cold-start overhead.\n",
    "    try:\n",
    "        results[0] = _process_record(agent, records[0])\n",
    "    except Exception as e:\n",
    "        pid = records[0].get(\"patient_id\") or records[0].get(\"id\")\n",
    "        results[0] = {\n",
    "            \"patient_id\": pid,\n",
    "            \"generated_response\": f\"- Decision: ROUTE FOR REVIEW\\n- Reason: processing error: {e}\"\n",
    "        }\n",
    "\n",
    "    # Submit the rest to a thread pool for concurrent processing\n",
    "    tasks = {}\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        for idx in range(1, len(records)):\n",
    "            # Keep track of which future maps to which record index so we can place results correctly\n",
    "            tasks[ex.submit(_process_record, agent, records[idx])] = idx\n",
    "\n",
    "        # As each future completes, store its result (or a fallback error) into `results` at the right index\n",
    "        for fut in as_completed(tasks):\n",
    "            idx = tasks[fut]\n",
    "            try:\n",
    "                results[idx] = fut.result()\n",
    "            except Exception as e:\n",
    "                pid = records[idx].get(\"patient_id\") or records[idx].get(\"id\")\n",
    "                results[idx] = {\n",
    "                    \"patient_id\": pid,\n",
    "                    \"generated_response\": f\"- Decision: ROUTE FOR REVIEW\\n- Reason: processing error: {e}\"\n",
    "                }\n",
    "\n",
    "    # Replace any remaining Nones with a neutral fallback to avoid downstream issues\n",
    "    for i, r in enumerate(results):\n",
    "        if r is None:\n",
    "            pid = records[i].get(\"patient_id\") or records[i].get(\"id\")\n",
    "            results[i] = {\n",
    "                \"patient_id\": pid,\n",
    "                \"generated_response\": \"- Decision: ROUTE FOR REVIEW\\n- Reason: unknown error.\"\n",
    "            }\n",
    "\n",
    "    return results  # ordered list aligned with input records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Validation & test runs ===\n",
    "\n",
    "# Run on validation set (if present) and print a tiny preview for sanity checking.\n",
    "if val_records:\n",
    "    start = time.time()\n",
    "    val_out = run_agent_on_records(agent, val_records, max_workers=6)\n",
    "    print(f\"Validation processed {len(val_out)} records in {time.time()-start:.2f}s (showing first 5):\")\n",
    "    for row in val_out[:5]:\n",
    "        # show patient id and just the first line (usually the Decision line)\n",
    "        first_line = row[\"generated_response\"].splitlines()[0] if row.get(\"generated_response\") else \"\"\n",
    "        print(row[\"patient_id\"], \"=>\", first_line)\n",
    "else:\n",
    "    # Keep behavior explicit to avoid silent no-ops for new users\n",
    "    print(\"No validation records found.\")\n",
    "\n",
    "# Ensure the output directory exists, then run on the test set and write the CSV required by the grader.\n",
    "os.makedirs(os.path.dirname(SUBMISSION_PATH), exist_ok=True)\n",
    "if test_records:\n",
    "    start = time.time()\n",
    "    test_results = run_agent_on_records(agent, test_records, max_workers=6)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"Test processed {len(test_results)} records in {elapsed:.2f} seconds\")\n",
    "    with open(SUBMISSION_PATH, 'w', newline='', encoding='utf-8') as f:\n",
    "        w = csv.DictWriter(f, fieldnames=['patient_id','generated_response'])  # required two columns\n",
    "        w.writeheader(); w.writerows(test_results)\n",
    "    print(f\"Wrote {SUBMISSION_PATH}\")\n",
    "else:\n",
    "    print(\"No test records found.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
